{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'sents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-408a00ed5c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m \u001b[0menron_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_synonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-408a00ed5c8c>\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(df_text)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mkey_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey_neg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'sents'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import networkx as nx\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.max_length = 50000000\n",
    "data = []\n",
    "with open('depression') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "dp = []\n",
    "for i in range(len(data)):\n",
    "    dp.append(data[i][0])\n",
    "    \n",
    "pos = []\n",
    "neg = []\n",
    "for j in range(len(dp)):\n",
    "    if dp[j]['label'] == 'control':\n",
    "        neg.append(dp[j])\n",
    "    else:\n",
    "        pos.append(dp[j])\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "for m in range(len(pos)):\n",
    "    pos[m] = pos[m]['posts']\n",
    "    \n",
    "for n in range(len(neg)):\n",
    "    neg[n] = neg[n]['posts']\n",
    "    \n",
    "h=0\n",
    "f=0\n",
    "for h in range(len(pos)):\n",
    "    for f in range(len(pos[h])):\n",
    "        pos[h][f] = pos[h][f][1]\n",
    "        \n",
    "g=0\n",
    "e=0\n",
    "for g in range(len(neg)):\n",
    "    for e in range(len(neg[g])):\n",
    "        neg[g][e] = neg[g][e][1]\n",
    "\n",
    "res = [''.join(ele) for ele in pos] \n",
    "ans = [''.join(ele) for ele in neg]\n",
    "\n",
    "res_1 = ' '.join(res)\n",
    "\n",
    "d_1 = {'date': [1],'email': res_1, 'sender': 'user1','time':[1]}\n",
    "df_text = pd.DataFrame(data=d_1)\n",
    "\n",
    "\n",
    "def read_json_file(fn):\n",
    "    f = open(fn, 'r')\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_json_file(data, fn):\n",
    "    f = open(fn, 'w')\n",
    "    json.dump(\n",
    "        data, f,\n",
    "        sort_keys=True,\n",
    "        indent=4,\n",
    "        separators=(',', ': '),\n",
    "    )\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "def read_pickle_file(fn):\n",
    "    f = open(fn, 'rb')\n",
    "    data = pickle.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_pickle_file(data, fn):\n",
    "    f = open(fn, 'wb')\n",
    "    pickle.dump(data, f, protocol=2)\n",
    "    f.close()\n",
    "    \n",
    "# df_text = df_1\n",
    "# nlp.max_length = len(df_1['email'][0])\n",
    "\n",
    "def remove_errors_from_text(text):\n",
    "    text = text.replace('=20\\r\\n', ' ')\n",
    "    text = text.replace('=\\r\\n', '')\n",
    "    text = text.replace('\\r\\n', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text\n",
    "\n",
    "def process_text(df_text):\n",
    "    data = []\n",
    "    vocabulary = set([])\n",
    "    \n",
    "    for index,row in df_text.iterrows():\n",
    "        text = remove_errors_from_text(row['email'])\n",
    "        #doc = nlp(text)\n",
    "        doc = text\n",
    "        sentences = []\n",
    "\n",
    "        key_neg = 'neg'\n",
    "        key_token = 'token'\n",
    "        key_en = 'en'\n",
    "        key_text = 'text'\n",
    "\n",
    "        for s in doc.sents:\n",
    "            sent = {key_neg:0, key_token:[],}\n",
    "            for token in s:\n",
    "                if token.is_alpha:\n",
    "                    if token.pos_ in ['ADJ', 'ADV', 'NOUN', 'VERB']:\n",
    "                        if token.is_stop:\n",
    "                            pass\n",
    "                        else:\n",
    "                            sent[key_token].append(token.lemma_)\n",
    "                            vocabulary.add(token.lemma_)\n",
    "                        if token.dep_ == 'neg':\n",
    "                            sent[key_neg] += 1\n",
    "            sent[key_text] = ' '.join(sent[key_token])\n",
    "            sentences.append(sent)\n",
    "        d = {'date':row['date'], 'sender':row['sender'], 'time':row['time']}\n",
    "        d['text'] = sentences\n",
    "        data.append(d)\n",
    "    return data, vocabulary\n",
    "\n",
    "enron_data, vocab = process_text(df_text)\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "                \n",
    "    synonyms = list(set(synonyms))\n",
    "    synonyms.sort()\n",
    " \n",
    "    return synonyms\n",
    "\n",
    "wn_vocabulary = {}\n",
    "\n",
    "for w in vocab:\n",
    "    syn = get_synonyms(w)\n",
    "    wn_vocabulary[w] = syn\n",
    "    \n",
    "def add_nodes(w, d):\n",
    "    if w in d:\n",
    "        d[w]['playcount'] += 1\n",
    "    else:\n",
    "        d[w] = {\n",
    "            'name':w,\n",
    "            \"match\": 1.0,\n",
    "            \"artist\": w,\n",
    "            \"id\": w,\n",
    "            'playcount':1,\n",
    "        }\n",
    "\n",
    "def gather_network_json(wn_vocabulary):\n",
    "    nodes = {}\n",
    "    links = set()\n",
    "    \n",
    "    for w in wn_vocabulary:\n",
    "        syn = wn_vocabulary[w]\n",
    "        if len(syn) > 0:\n",
    "            add_nodes(w, nodes)\n",
    "            for s in syn:\n",
    "                if s != w:\n",
    "                    if ('_' not in s) and ('-' not in s):\n",
    "                        add_nodes(s, nodes)\n",
    "                        edge  = (w,s)\n",
    "                        redge = (s,w)\n",
    "                        if redge not in links:\n",
    "                            links.add(edge)\n",
    "                            nodes[w]['playcount'] += 1\n",
    "                    \n",
    "    nodes_list = []\n",
    "    links_list = []\n",
    "    for n in nodes:\n",
    "        nodes_list.append(nodes[n])\n",
    "    for w,s in list(links):\n",
    "        links_list.append({\n",
    "            \"source\": w,\n",
    "            \"target\": s,\n",
    "        })\n",
    "        \n",
    "    data = {'nodes':nodes_list, 'links':links_list}\n",
    "    return nodes, links, data\n",
    "\n",
    "wn_nodes, wn_links, wn_net = gather_network_json(wn_vocabulary)\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(list(wn_links))\n",
    "\n",
    "#dictionary_path = os.path.join(os.path.dirname(cwd), 'data')\n",
    "\n",
    "#emo12_liwc = os.path.join(dictionary_path, 'twelve_emotions_liwc.json')\n",
    "#emo12_liwc = read_json_file(emo12_liwc)\n",
    "emo12_liwc = read_json_file('twelve_emotions_liwc.json')\n",
    "#emo12_extd = read_pickle_file(os.path.join(dictionary_path, 'extended_emotions.pkl'))\n",
    "emo12_extd = read_pickle_file('extended_emotions.pkl')\n",
    "enron_words_list = [w for w in wn_nodes]\n",
    "enron_words_str = ' '.join(enron_words_list)\n",
    "\n",
    "def is_word(t):\n",
    "    reg = r'[a-zA-Z]+'\n",
    "    r = re.match(reg, t)\n",
    "    if r is None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def search_minimal_item(t, s):\n",
    "    reg = t\n",
    "    if '*' in reg:\n",
    "        reg = reg.replace('*', '')\n",
    "        if is_word(reg):\n",
    "            reg = r'\\s+('+r'{0}'.format(reg)+r'\\S*)'\n",
    "            r = re.findall(reg, s)\n",
    "            return r\n",
    "    else:\n",
    "        if is_word(reg):\n",
    "            return [reg] \n",
    "    return []\n",
    "\n",
    "emo12_category = list(emo12_liwc.keys())\n",
    "emo12_category.sort()\n",
    "\n",
    "emo12_enron = {}\n",
    "\n",
    "for category in emo12_category:\n",
    "    group = emo12_liwc[category]\n",
    "    group.sort()\n",
    "    emo12_enron[category] = {}\n",
    "    for w in group:\n",
    "        extend_words = search_minimal_item(w, enron_words_str)\n",
    "        extend_words = list(set(extend_words))\n",
    "        extend_words.sort()\n",
    "        emo12_enron[category][w] = extend_words\n",
    "\n",
    "emo12_enron_list = {}\n",
    "for category in emo12_enron:\n",
    "    group = emo12_enron[category]\n",
    "    emo12_enron_list[category] = []\n",
    "    for key in group:\n",
    "        ls = group[key]\n",
    "        emo12_enron_list[category].extend(ls)\n",
    "\n",
    "emo12_enron_list_neighbors = {}\n",
    "emo12_enron_list_neighbors_dict = {}\n",
    "word_nodes = G.nodes()\n",
    "\n",
    "for category in emo12_category:\n",
    "    group = emo12_enron_list[category]\n",
    "    emo12_enron_list_neighbors[category] = []\n",
    "    emo12_enron_list_neighbors_dict[category] = {}\n",
    "    for w in group:\n",
    "        if w in word_nodes:\n",
    "            for i in G.neighbors(w):\n",
    "                ii = i.lower()\n",
    "                emo12_enron_list_neighbors_dict[category][w] = []\n",
    "                if ii not in group:\n",
    "                    emo12_enron_list_neighbors[category].append(ii)\n",
    "                    emo12_enron_list_neighbors_dict[category][w].append(ii)\n",
    "                    \n",
    "                    \n",
    "for category in emo12_category:\n",
    "    emo12_enron_list_neighbors[category] = list(set(emo12_enron_list_neighbors[category]))\n",
    "    emo12_enron_list_neighbors[category].sort()\n",
    "\n",
    "enron_emo12_word_label = {}\n",
    "\n",
    "def found_emotion(w, d):\n",
    "    for c in d:\n",
    "        if w in d[c]:\n",
    "            return c\n",
    "        \n",
    "    return 'NA'\n",
    "\n",
    "for w in wn_nodes:\n",
    "    e = found_emotion(w, emo12_enron_list)\n",
    "    if e == 'NA':\n",
    "        e = found_emotion(w, emo12_extd)\n",
    "        \n",
    "    if e != 'NA':\n",
    "        enron_emo12_word_label[w] = e\n",
    "        \n",
    "email_sent_data = []\n",
    "\n",
    "def add_emotion(w, d, r, t):\n",
    "    pre = 'Word-'\n",
    "    \n",
    "    if w not in d:\n",
    "        return\n",
    "    \n",
    "    e = d[w]\n",
    "    if e in r:\n",
    "        r[e] += 1\n",
    "        t[pre+e].append(w)\n",
    "    else:\n",
    "        r[e]  = 1\n",
    "        t[pre+e] = [w]\n",
    "\n",
    "for d in enron_data:\n",
    "    d_sender  = d['sender']\n",
    "    d_date    = d['date']\n",
    "    d_time    = d['time']\n",
    "    sentences = d['text']\n",
    "    for sent in sentences:\n",
    "        d_neg = sent['neg']\n",
    "        words = sent['token']\n",
    "        d_emo = {}\n",
    "        d_tgt = {}\n",
    "        for w in words:\n",
    "            add_emotion(w, enron_emo12_word_label, d_emo, d_tgt)\n",
    "        for k in d_tgt:\n",
    "            d_tgt[k] = ' '.join(d_tgt[k])\n",
    "        d_emo.update(d_tgt)\n",
    "        d_emo['sender'] = d_sender\n",
    "        d_emo['date']   = d_date\n",
    "        d_emo['time']   = d_time\n",
    "        d_emo['neg']    = d_neg\n",
    "        d_emo['text']   = sent['text']\n",
    "        \n",
    "        email_sent_data.append(d_emo)\n",
    "        \n",
    "email_sent_data_df = pandas.DataFrame(email_sent_data)\n",
    "email_sent_data_df.fillna(0, inplace=True)\n",
    "\n",
    "email_sent_data_df.to_csv('lklk4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-525f883a08ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0md_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'email'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sender'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'user1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mdf_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_1' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import networkx as nx\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 50000000\n",
    "data = []\n",
    "with open('depression') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "dp = []\n",
    "for i in range(len(data)):\n",
    "    dp.append(data[i][0])\n",
    "    \n",
    "pos = []\n",
    "neg = []\n",
    "for j in range(len(dp)):\n",
    "    if dp[j]['label'] == 'control':\n",
    "        neg.append(dp[j])\n",
    "    else:\n",
    "        pos.append(dp[j])\n",
    "\n",
    "m = 0\n",
    "n = 0\n",
    "for m in range(len(pos)):\n",
    "    pos[m] = pos[m]['posts']\n",
    "    \n",
    "for n in range(len(neg)):\n",
    "    neg[n] = neg[n]['posts']\n",
    "    \n",
    "h=0\n",
    "f=0\n",
    "for h in range(len(pos)):\n",
    "    for f in range(len(pos[h])):\n",
    "        pos[h][f] = pos[h][f][1]\n",
    "        \n",
    "g=0\n",
    "e=0\n",
    "for g in range(len(neg)):\n",
    "    for e in range(len(neg[g])):\n",
    "        neg[g][e] = neg[g][e][1]\n",
    "\n",
    "res = [''.join(ele) for ele in pos] \n",
    "ans = [''.join(ele) for ele in neg]\n",
    "\n",
    "res_1 = ' '.join(res)\n",
    "\n",
    "d_1 = {'date': [1],'email': res_1, 'sender': 'user1','time':[1]}\n",
    "df_text = pd.DataFrame(data=d_1)\n",
    "df_1.to_csv(\"check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.to_csv(\"check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo12_liwc = read_json_file('twelve_emotions_liwc.json')\n",
    "#emo12_extd = read_pickle_file(os.path.join(dictionary_path, 'extended_emotions.pkl'))\n",
    "emo12_extd = read_pickle_file('extended_emotions.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shame': ['ashamed', 'guilt', 'guiltiness'],\n",
       " 'Interest': ['foolproof',\n",
       "  'tireless',\n",
       "  'untiring',\n",
       "  'unflagging',\n",
       "  'industrious',\n",
       "  'unfailing',\n",
       "  'indefatigable',\n",
       "  'energetic',\n",
       "  'unwearying',\n",
       "  'hardworking',\n",
       "  'gumptious',\n",
       "  'goofproof',\n",
       "  'provocative',\n",
       "  'excitedly',\n",
       "  'sexiest',\n",
       "  'aphrodisiac',\n",
       "  'sexy',\n",
       "  'aphrodisiacal',\n",
       "  'vivacious',\n",
       "  'vibrant',\n",
       "  'thirstily',\n",
       "  'eagerly',\n",
       "  'considerate',\n",
       "  'enthusiastic',\n",
       "  'actively',\n",
       "  'importantly',\n",
       "  'significantly'],\n",
       " 'Sadness': ['stillborn',\n",
       "  'abortive',\n",
       "  'unsuccessful',\n",
       "  'loners',\n",
       "  'loner',\n",
       "  'nonstarter',\n",
       "  'loser',\n",
       "  'failure',\n",
       "  'bankruptcies',\n",
       "  'failures',\n",
       "  'losers',\n",
       "  'bankruptcy',\n",
       "  'uninterested',\n",
       "  'goober',\n",
       "  'undistinguished',\n",
       "  'peanut',\n",
       "  'unimportant',\n",
       "  'groundnuts',\n",
       "  'groundnut',\n",
       "  'truffle',\n",
       "  'insignificant',\n",
       "  'peanuts',\n",
       "  'earthnut',\n",
       "  'cataclysm',\n",
       "  'calamities',\n",
       "  'tragedy',\n",
       "  'disaster',\n",
       "  'tragedies',\n",
       "  'catastrophes',\n",
       "  'disasters',\n",
       "  'catastrophe',\n",
       "  'calamity',\n",
       "  'wuss',\n",
       "  'weakling',\n",
       "  'doormat',\n",
       "  'paralytic',\n",
       "  'paralyse',\n",
       "  'paralyze',\n",
       "  'paralytical',\n",
       "  'paralyzed',\n",
       "  'paralysed',\n",
       "  'paralyzes',\n",
       "  'paralysing',\n",
       "  'miser',\n",
       "  'misers',\n",
       "  'disillusioning',\n",
       "  'disenchanting',\n",
       "  'disenchanted',\n",
       "  'disillusion',\n",
       "  'disillusioned',\n",
       "  'disenchant',\n",
       "  'disillusionment',\n",
       "  'disenchantment',\n",
       "  'disgruntle',\n",
       "  'dissatisfy',\n",
       "  'dissatisfied',\n",
       "  'disgruntled',\n",
       "  'doleful',\n",
       "  'plaintive',\n",
       "  'mournful',\n",
       "  'lifeless',\n",
       "  'exanimate',\n",
       "  'useless',\n",
       "  'woefully',\n",
       "  'sadly',\n",
       "  'unhappily',\n",
       "  'deplorably',\n",
       "  'lamentably',\n",
       "  'heartsick',\n",
       "  'heartbroken',\n",
       "  'despondent',\n",
       "  'brokenhearted',\n",
       "  'pessimistic',\n",
       "  'ignoramus',\n",
       "  'martyrise',\n",
       "  'martyrs',\n",
       "  'martyr',\n",
       "  'martyrize',\n",
       "  'sufferer',\n",
       "  'sufferers',\n",
       "  'distrustful',\n",
       "  'insensitive',\n",
       "  'gloomily',\n",
       "  'inappropriateness',\n",
       "  'wrongness',\n",
       "  'unworthiness',\n",
       "  'pitifully',\n",
       "  'disinterested',\n",
       "  'remorse',\n",
       "  'compunctions',\n",
       "  'compunction',\n",
       "  'sleepy',\n",
       "  'sleepyheaded',\n",
       "  'sleepiest',\n",
       "  'sorrowful',\n",
       "  'vulnerable',\n",
       "  'uselessness',\n",
       "  'unusefulness',\n",
       "  'inutility',\n",
       "  'powerless',\n",
       "  'ruthful',\n",
       "  'remorseful',\n",
       "  'contrite',\n",
       "  'rueful',\n",
       "  'hopeless',\n",
       "  'tragically',\n",
       "  'inferiority',\n",
       "  'inferiorities',\n",
       "  'forlorn',\n",
       "  'uselessly',\n",
       "  'unenrgetic',\n",
       "  'lethargic',\n",
       "  'pitiably',\n",
       "  'pathetically',\n",
       "  'coldly',\n",
       "  'tragical',\n",
       "  'tragic',\n",
       "  'homesick'],\n",
       " 'Pride': ['courageousness',\n",
       "  'courage',\n",
       "  'fearlessness',\n",
       "  'bravery',\n",
       "  'braveness',\n",
       "  'excellences',\n",
       "  'excellency',\n",
       "  'excellencies',\n",
       "  'excellence',\n",
       "  'heroism',\n",
       "  'heroisms',\n",
       "  'chivalry',\n",
       "  'valiancy',\n",
       "  'valorousness',\n",
       "  'knightliness',\n",
       "  'valor',\n",
       "  'valours',\n",
       "  'politesse',\n",
       "  'gallantries',\n",
       "  'valour',\n",
       "  'valiance',\n",
       "  'gallantry',\n",
       "  'gorgeously',\n",
       "  'resplendently',\n",
       "  'excellently',\n",
       "  'splendidly',\n",
       "  'famously',\n",
       "  'magnificently',\n",
       "  'sagely',\n",
       "  'wisely',\n",
       "  'successful',\n",
       "  'originative',\n",
       "  'seminal',\n",
       "  'creative',\n",
       "  'germinal',\n",
       "  'flawless',\n",
       "  'unflawed',\n",
       "  'boldly',\n",
       "  'healer',\n",
       "  'therapists',\n",
       "  'therapist',\n",
       "  'creativity',\n",
       "  'creativeness',\n",
       "  'heroine',\n",
       "  'proudly',\n",
       "  'successfully'],\n",
       " 'Fear': ['whiner',\n",
       "  'grumbler',\n",
       "  'chickens',\n",
       "  'complainer',\n",
       "  'sniveller',\n",
       "  'yellow',\n",
       "  'yellowness',\n",
       "  'yellower',\n",
       "  'squawker',\n",
       "  'moaner',\n",
       "  'xanthous',\n",
       "  'volaille',\n",
       "  'chicken',\n",
       "  'complainers',\n",
       "  'bellyacher',\n",
       "  'yellowing',\n",
       "  'wimp',\n",
       "  'yellowish',\n",
       "  'crybaby',\n",
       "  'scandalmongering',\n",
       "  'chickenhearted',\n",
       "  'jaundiced',\n",
       "  'poulet',\n",
       "  'yellowed',\n",
       "  'sensationalistic',\n",
       "  'icteric',\n",
       "  'unassumingness',\n",
       "  'seriousness',\n",
       "  'sincerity',\n",
       "  'earnestness',\n",
       "  'distressfulness',\n",
       "  'tentative',\n",
       "  'doubtful',\n",
       "  'dubitable',\n",
       "  'dubious',\n",
       "  'provisional',\n",
       "  'probationary',\n",
       "  'provisionary',\n",
       "  'harmful',\n",
       "  'unprotected',\n",
       "  'hazardously',\n",
       "  'perilously',\n",
       "  'dangerously',\n",
       "  'petrify',\n",
       "  'petrified',\n",
       "  'ossify',\n",
       "  'rigidify',\n",
       "  'lapidify',\n",
       "  'afraid'],\n",
       " 'Anxiety': ['fretful',\n",
       "  'querulous',\n",
       "  'fidgety',\n",
       "  'whiney',\n",
       "  'whiny',\n",
       "  'itchy',\n",
       "  'antsy',\n",
       "  'rigidness',\n",
       "  'inflexibleness',\n",
       "  'rigidity',\n",
       "  'inflexibility',\n",
       "  'bleated',\n",
       "  'blate',\n",
       "  'bleatings',\n",
       "  'bleat',\n",
       "  'bleats',\n",
       "  'blat',\n",
       "  'bleating',\n",
       "  'baa',\n",
       "  'bashful',\n",
       "  'bashfully',\n",
       "  'shyly',\n",
       "  'timidly',\n",
       "  'justificative',\n",
       "  'justificatory',\n",
       "  'defensive',\n",
       "  'indecisive',\n",
       "  'neurotic',\n",
       "  'psychoneurotic',\n",
       "  'apprehensively',\n",
       "  'uneasily',\n",
       "  'anxiously',\n",
       "  'distraught',\n",
       "  'overwrought',\n",
       "  'defensively',\n",
       "  'tensely',\n",
       "  'nervously',\n",
       "  'defensiveness',\n",
       "  'uncomfortable',\n",
       "  'irrational',\n",
       "  'shyness',\n",
       "  'confusedly',\n",
       "  'ambivalent'],\n",
       " 'Relief': ['peacefully', 'assur', 'ashir', 'asur', 'ashur', 'safely'],\n",
       " 'Anger': ['hoggishness',\n",
       "  'cupidity',\n",
       "  'greed',\n",
       "  'greediness',\n",
       "  'ravenousness',\n",
       "  'avarice',\n",
       "  'avaritia',\n",
       "  'rapaciousness',\n",
       "  'voraciousness',\n",
       "  'edacity',\n",
       "  'rapacity',\n",
       "  'voracity',\n",
       "  'esurience',\n",
       "  'covetousness',\n",
       "  'avariciousness',\n",
       "  'piggishness',\n",
       "  'avenge',\n",
       "  'retaliating',\n",
       "  'avenged',\n",
       "  'retaliation',\n",
       "  'revenges',\n",
       "  'revenge',\n",
       "  'avenging',\n",
       "  'revenging',\n",
       "  'retaliate',\n",
       "  'revenged',\n",
       "  'retaliated',\n",
       "  'aggressors',\n",
       "  'assaulter',\n",
       "  'aggressor',\n",
       "  'attackers',\n",
       "  'attacker',\n",
       "  'assailants',\n",
       "  'assailant',\n",
       "  'exceptionable',\n",
       "  'objectionable',\n",
       "  'obnoxious',\n",
       "  'aggressions',\n",
       "  'antagonisms',\n",
       "  'enmities',\n",
       "  'belligerency',\n",
       "  'hostilities',\n",
       "  'antagonism',\n",
       "  'hostility',\n",
       "  'aggressiveness',\n",
       "  'aggression',\n",
       "  'enmity',\n",
       "  'belligerence',\n",
       "  'pugnacity',\n",
       "  'agnostical',\n",
       "  'skeptics',\n",
       "  'sceptic',\n",
       "  'sceptics',\n",
       "  'doubter',\n",
       "  'agnostics',\n",
       "  'agnostic',\n",
       "  'doubters',\n",
       "  'skeptic',\n",
       "  'nostalgic',\n",
       "  'avariciously',\n",
       "  'covetously',\n",
       "  'greedily',\n",
       "  'jealously',\n",
       "  'enviously',\n",
       "  'destructive',\n",
       "  'jealousy',\n",
       "  'jealousies',\n",
       "  'ireful',\n",
       "  'irate',\n",
       "  'feuds',\n",
       "  'feud',\n",
       "  'haters',\n",
       "  'hater'],\n",
       " 'Agreeableness': ['fondly',\n",
       "  'lovingly',\n",
       "  'supportive',\n",
       "  'mixers',\n",
       "  'societal',\n",
       "  'social',\n",
       "  'mixer',\n",
       "  'sociable',\n",
       "  'amative',\n",
       "  'amorous',\n",
       "  'quixotic',\n",
       "  'romanticist',\n",
       "  'romantic',\n",
       "  'sentimentalists',\n",
       "  'sentimentalist',\n",
       "  'amatory',\n",
       "  'romanticistic',\n",
       "  'romantics',\n",
       "  'courteously',\n",
       "  'politely',\n",
       "  'beautiful',\n",
       "  'modishly',\n",
       "  'smartly',\n",
       "  'cleverly',\n",
       "  'sprucely',\n",
       "  'vigorously',\n",
       "  'loveliest',\n",
       "  'endear',\n",
       "  'endearing',\n",
       "  'lovelies',\n",
       "  'lovely',\n",
       "  'adorable',\n",
       "  'lovelier',\n",
       "  'endeared',\n",
       "  'positively',\n",
       "  'trustiest',\n",
       "  'trusty',\n",
       "  'trustworthy',\n",
       "  'playfully',\n",
       "  'dignities',\n",
       "  'gravitas',\n",
       "  'dignity',\n",
       "  'hauteur',\n",
       "  'haughtiness',\n",
       "  'lordliness',\n",
       "  'arrogance',\n",
       "  'sociableness',\n",
       "  'sociability',\n",
       "  'coquettish',\n",
       "  'flirtatious',\n",
       "  'tenderly',\n",
       "  'gorgeous',\n",
       "  'usefully',\n",
       "  'utile',\n",
       "  'useful',\n",
       "  'utilitarian',\n",
       "  'passionate',\n",
       "  'respectful',\n",
       "  'venerating',\n",
       "  'reverential',\n",
       "  'powerfully',\n",
       "  'strongly',\n",
       "  'potently',\n",
       "  'spruceness',\n",
       "  'neatness',\n",
       "  'tidiness',\n",
       "  'respectfully',\n",
       "  'nicely',\n",
       "  'handsomely'],\n",
       " 'Joy': ['pleasant',\n",
       "  'pleasantest',\n",
       "  'pleasanter',\n",
       "  'grins',\n",
       "  'smiling',\n",
       "  'smiles',\n",
       "  'grinning',\n",
       "  'beamish',\n",
       "  'grinned',\n",
       "  'smiled',\n",
       "  'grin',\n",
       "  'smile',\n",
       "  'twinkly',\n",
       "  'fab',\n",
       "  'faber',\n",
       "  'fabulous',\n",
       "  'mythologic',\n",
       "  'mythic',\n",
       "  'mythical',\n",
       "  'mythological',\n",
       "  'especially',\n",
       "  'interrogatively',\n",
       "  'funnily',\n",
       "  'queerly',\n",
       "  'fishily',\n",
       "  'curiously',\n",
       "  'particularly',\n",
       "  'inquisitively',\n",
       "  'peculiarly',\n",
       "  'oddly',\n",
       "  'specially',\n",
       "  'strangely',\n",
       "  'gayly',\n",
       "  'happily',\n",
       "  'merrily',\n",
       "  'mirthfully',\n",
       "  'blithely',\n",
       "  'jubilantly',\n",
       "  'felicity',\n",
       "  'felicities',\n",
       "  'felicitousness',\n",
       "  'happiness',\n",
       "  'overjoyed',\n",
       "  'overjoy',\n",
       "  'merit',\n",
       "  'virtuousness',\n",
       "  'deservingness',\n",
       "  'deservings',\n",
       "  'chastity',\n",
       "  'meritoriousness',\n",
       "  'deserved',\n",
       "  'merits',\n",
       "  'merited',\n",
       "  'deserves',\n",
       "  'celibacy',\n",
       "  'virtue',\n",
       "  'worth',\n",
       "  'deserving',\n",
       "  'virtues',\n",
       "  'deserve',\n",
       "  'hooray',\n",
       "  'hurrah',\n",
       "  'hurrahs',\n",
       "  'amazingly',\n",
       "  'surprisingly',\n",
       "  'astonishingly',\n",
       "  'thanksss',\n",
       "  'thank',\n",
       "  'thanking',\n",
       "  'thanks',\n",
       "  'thanked',\n",
       "  'thankes',\n",
       "  'incredibly',\n",
       "  'fantastically',\n",
       "  'implausibly',\n",
       "  'improbably',\n",
       "  'fabulously',\n",
       "  'unbelievably',\n",
       "  'bliss',\n",
       "  'blissfulness',\n",
       "  'blissful',\n",
       "  'appreciative',\n",
       "  'thankfully',\n",
       "  'gratefully',\n",
       "  'appreciatively',\n",
       "  'frisky',\n",
       "  'kittenish',\n",
       "  'joyous',\n",
       "  'thankful',\n",
       "  'grateful',\n",
       "  'playful',\n",
       "  'yay'],\n",
       " 'Contentment': ['unimpeachably',\n",
       "  'definitely',\n",
       "  'unquestionably',\n",
       "  'decidedly',\n",
       "  'emphatically',\n",
       "  'helpfulness',\n",
       "  'kindliness',\n",
       "  'helpful',\n",
       "  'optima',\n",
       "  'optimal',\n",
       "  'optimum',\n",
       "  'enjoyably',\n",
       "  'agreeably',\n",
       "  'pleasantly',\n",
       "  'sunnily',\n",
       "  'cheerily',\n",
       "  'health',\n",
       "  'wellness',\n",
       "  'radian',\n",
       "  'rad',\n",
       "  'rads',\n",
       "  'fortuitously',\n",
       "  'fortunately',\n",
       "  'luckily',\n",
       "  'confidently',\n",
       "  'freely',\n",
       "  'honestness',\n",
       "  'satinpod',\n",
       "  'honesty',\n",
       "  'forgave',\n",
       "  'forgives',\n",
       "  'absolvitory',\n",
       "  'forgiven',\n",
       "  'forgiving',\n",
       "  'exonerative',\n",
       "  'forgive',\n",
       "  'contentment',\n",
       "  'optimism',\n",
       "  'worthwhile',\n",
       "  'helpfully',\n",
       "  'hopefully'],\n",
       " 'Disgust': ['lunkhead',\n",
       "  'hammerhead',\n",
       "  'knucklehead',\n",
       "  'bonehead',\n",
       "  'dumbass',\n",
       "  'shithead',\n",
       "  'blockheads',\n",
       "  'fuckhead',\n",
       "  'muttonhead',\n",
       "  'knuckleheads',\n",
       "  'dunderhead',\n",
       "  'numskull',\n",
       "  'dunce',\n",
       "  'loggerhead',\n",
       "  'loggerheads',\n",
       "  'dunces',\n",
       "  'blockhead',\n",
       "  'mockers',\n",
       "  'scoffers',\n",
       "  'scoffer',\n",
       "  'mockingbird',\n",
       "  'flouter',\n",
       "  'gorger',\n",
       "  'mocker',\n",
       "  'jeerer',\n",
       "  'nonnatural',\n",
       "  'wyrd',\n",
       "  'apparitional',\n",
       "  'phantasmal',\n",
       "  'religious',\n",
       "  'spectral',\n",
       "  'eldritch',\n",
       "  'ghostly',\n",
       "  'unearthly',\n",
       "  'weirder',\n",
       "  'uncanny',\n",
       "  'transcendental',\n",
       "  'otherworldly',\n",
       "  'spirituals',\n",
       "  'preternatural',\n",
       "  'spiritual',\n",
       "  'ghostlike',\n",
       "  'weirdest',\n",
       "  'weird',\n",
       "  'savagely',\n",
       "  'brutally',\n",
       "  'viciously',\n",
       "  'atrocities',\n",
       "  'inhumanities',\n",
       "  'barbarism',\n",
       "  'barbarity',\n",
       "  'ferociousness',\n",
       "  'atrocity',\n",
       "  'savageness',\n",
       "  'brutality',\n",
       "  'brutalities',\n",
       "  'atrociousness',\n",
       "  'inhumanity',\n",
       "  'barbarousness',\n",
       "  'savagery',\n",
       "  'inhumaneness',\n",
       "  'viciousness',\n",
       "  'barbarisms',\n",
       "  'heinousness',\n",
       "  'violently',\n",
       "  'rapists',\n",
       "  'rapist',\n",
       "  'raper',\n",
       "  'raring',\n",
       "  'impatient',\n",
       "  'impolitely',\n",
       "  'discourteously',\n",
       "  'rudely',\n",
       "  'impolite',\n",
       "  'unwisely',\n",
       "  'foolishly',\n",
       "  'evilly',\n",
       "  'wickedly',\n",
       "  'villain',\n",
       "  'scoundrels',\n",
       "  'scoundrel',\n",
       "  'villains',\n",
       "  'baddie',\n",
       "  'selfish',\n",
       "  'enviousness',\n",
       "  'invidia',\n",
       "  'resenting',\n",
       "  'resented',\n",
       "  'envied',\n",
       "  'begrudge',\n",
       "  'envyings',\n",
       "  'envying',\n",
       "  'envies',\n",
       "  'envy',\n",
       "  'resent',\n",
       "  'loveless',\n",
       "  'ingenuously',\n",
       "  'inexpertly',\n",
       "  'artlessly',\n",
       "  'crudely',\n",
       "  'grimly',\n",
       "  'unpleasant',\n",
       "  'unpleasantest',\n",
       "  'pitiless',\n",
       "  'ruthless',\n",
       "  'unkind',\n",
       "  'remorseless',\n",
       "  'unpitying',\n",
       "  'messy',\n",
       "  'mussy',\n",
       "  'displeased',\n",
       "  'displease',\n",
       "  'displeases',\n",
       "  'unfeeling',\n",
       "  'heartless',\n",
       "  'stonyhearted',\n",
       "  'hardhearted',\n",
       "  'prevaricator',\n",
       "  'liars',\n",
       "  'liar',\n",
       "  'teas',\n",
       "  'teatime',\n",
       "  'tea',\n",
       "  'doltishly',\n",
       "  'stupidly',\n",
       "  'bizarreness',\n",
       "  'outlandishness',\n",
       "  'weirdness',\n",
       "  'animus',\n",
       "  'animosities',\n",
       "  'animosity',\n",
       "  'faultfinder',\n",
       "  'cynics',\n",
       "  'cynic',\n",
       "  'unjust',\n",
       "  'unfair',\n",
       "  'inequitable',\n",
       "  'untempting',\n",
       "  'uninviting',\n",
       "  'unattractive',\n",
       "  'smug',\n",
       "  'fucker',\n",
       "  'fuckers',\n",
       "  'weirdly',\n",
       "  'grossly',\n",
       "  'resentful',\n",
       "  'nast']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emo12_extd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
